from flask import Flask, request, jsonify
from flask_cors import CORS
import spacy
import re
import os

app = Flask(__name__)
CORS(app)  

print("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ª–æ–∫–∞–ª—å–Ω–æ–π AI –º–æ–¥–µ–ª–∏...")

try:
    nlp = spacy.load("ru_core_news_md")
    print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å spaCy: ru_core_news_md")
except OSError:
    try:
        nlp = spacy.load("ru_core_news_sm")
        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å spaCy: ru_core_news_sm")
    except OSError:
        print("–ú–æ–¥–µ–ª–∏ spaCy –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        os.system("python -m spacy download ru_core_news_sm")
        nlp = spacy.load("ru_core_news_sm")
        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ –º–æ–¥–µ–ª—å spaCy: ru_core_news_sm")


patterns = {
    "–ò–ò–ù": r"\b\d{12}\b",
    "EMAIL": r"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}",
    "–¢–ï–õ–ï–§–û–ù": r"(\+7|8)[0-9]{10}",
    "–ü–ê–°–ü–û–†–¢": r"\b\d{9}\b",
    "–ö–ê–†–¢–ê": r"\b\d{16}\b",
    "–î–ê–¢–ê –†–û–ñ–î–ï–ù–ò–Ø": r"\b\d{2}[./-]\d{2}[./-]\d{4}\b",
    "–ê–î–†–ï–°": r"(?:—É–ª\.|—É–ª–∏—Ü–∞|–ø—Ä–æ—Å–ø–µ–∫—Ç|–ø—Ä\.|–º–∏–∫—Ä–æ—Ä–∞–π–æ–Ω|–º–∫—Ä\.|–ø—Ä-—Ç)\s+[\w–ê-–Ø–∞-—è\-]+(?:\s*,?\s*(?:–¥–æ–º|–¥\.|—É—á\.)?\s*\d+)?(?:\s*,?\s*(?:–∫–≤\.|–∫–≤–∞—Ä—Ç–∏—Ä–∞|–æ—Ñ–∏—Å|–æ—Ñ\.)?\s*\d+)?",
    "PERSON": r"[–ê-–Ø][–∞-—è]+ [–ê-–Ø][–∞-—è]+(?:–æ–≤|–µ–≤|–∏–Ω|–æ–≤–∞|–µ–≤–∞|–∏–Ω–∞|–∫—ã–∑—ã|—É–ª—ã)?",
    "ORG": r"(?:TOO|–¢–û–û|–ê–û|–ò–ü)\s+[\"'][\w–ê-–Ø–∞-—è\s\-]+[\"']",
}

def analyze_text_with_regex(text):
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é —Ä–µ–≥—É–ª—è—Ä–Ω—ã—Ö –≤—ã—Ä–∞–∂–µ–Ω–∏–π"""
    entities = []
    
    for label, pattern in patterns.items():
        for match in re.finditer(pattern, text):
            entities.append({
                "text": match.group(),
                "label": label
            })
    
    return entities

def analyze_text_with_spacy(text):
    """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é SpaCy"""
    doc = nlp(text)
    entities = []
    

    label_map = {
        "PER": "PERSON", 
        "PERSON": "PERSON",
        "ORG": "ORG",
        "LOC": "LOC",
        "GPE": "GPE",
        "MONEY": "–§–ò–ù–ê–ù–°–´",
        "DATE": "–î–ê–¢–ê"
    }
    
    for ent in doc.ents:
        if ent.label_ in label_map:
            entities.append({
                "text": ent.text,
                "label": label_map[ent.label_]
            })
    
    return entities

@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ —Å–µ—Ä–≤–µ—Ä–∞"""
    return jsonify({"status": "ok"})

@app.route('/analyze', methods=['POST'])
def analyze():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    try:
        data = request.json
        
        if not data or 'text' not in data:
            return jsonify({"error": "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ 'text'"}), 400
        
        text = data['text']
        print(f"–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ ({len(text)} —Å–∏–º–≤–æ–ª–æ–≤)")
        
        regex_entities = analyze_text_with_regex(text)
        spacy_entities = analyze_text_with_spacy(text)
        
        all_entities = regex_entities + spacy_entities
        unique_entities = []
        seen_texts = set()
        
        for entity in all_entities:
            entity_key = f"{entity['text']}_{entity['label']}"
            if entity_key not in seen_texts:
                seen_texts.add(entity_key)
                unique_entities.append(entity)
        
        print(f"–ù–∞–π–¥–µ–Ω–æ {len(unique_entities)} —Å—É—â–Ω–æ—Å—Ç–µ–π")
        
        return jsonify({"entities": unique_entities})
    
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞: {e}")
        return jsonify({"error": str(e)}), 500

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ AI-—Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è –∞–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞ http://localhost:5000")
    app.run(host='0.0.0.0', port=5000, debug=True)